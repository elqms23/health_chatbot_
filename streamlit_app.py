<<<<<<< HEAD
import streamlit as st
from src.chatbot import HealthChatbot

# Sidebar for model settings
st.sidebar.title("­ЪћД Settings")
model = st.sidebar.selectbox("LLM Model", ["gpt-3.5-turbo", "llama3.2", "mistral"])
prompt_type = st.sidebar.selectbox("Prompt Style", ["basic", "enhanced", "medication"])

# Title & description
st.title("­ЪЕ║ Health Management Chatbot")
st.markdown("Ask health-related questions based on patient FHIR records.")

# Load chatbot
@st.cache_resource
def load_chatbot():
    return HealthChatbot(
        vector_db_path="vector_db",
        model_name=model,
        prompt_type=prompt_type
    )

chatbot = load_chatbot()

# User input
query = st.text_input("­Ъњг Enter your health question:")
patient_id = st.text_input("­Ъєћ Patient ID (optional):")

# Ask button
if st.button("Ask"):
    if not query.strip():
        st.warning("Please enter a question.")
    else:
        with st.spinner("Processing..."):
            try:
                response = chatbot.get_answer(query, patient_id or None)
                st.markdown("### ­ЪДа Chatbot Response")
                st.markdown(response)
            except Exception as e:
                st.error(f"An error occurred: {e}")
